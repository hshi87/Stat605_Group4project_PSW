---
title: "Preliminary_presentation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load the packages

```{r,load_packages}
rm(list=ls())
library(tuneR)
library(oce)
library(seewave)
library(signal)
```

The above are the packages we might need.

# Data Description

We can use kaggle API to download the dataset.

!kaggle datasets download gopidurgaprasad/birdsong2-wav16k-00 

The whole datasets is 26 GB.

```{r, dataset}
setwd("~/stat605/group4")
path = "tmp/birdsongWav/train2_wav16k_00/"
all_dirs = list.dirs(path)
all_files = list.files(path)
print(all_files)
count = 0
for (file_dir in all_dirs){
  count = count + length(list.files(file_dir))
}
print(paste("Total we have",length(all_files), "bird categories."))
print(paste("Total we have",count, "files."))
```

[ebird.org](https://ebird.org/home) is a website for us to find the corresponding bird by above abbreviation.

## Read the data (Variables type)

```{r, read_data}
sample_audio = readWave(paste0(path,'aldfly/XC16964.wav'))
plot(sample_audio@left,type ='l', col = 'seagreen', xlab = 'Elements / Time', ylab = 'Freq', main = 'Audio Frequency Wave')
summary(sample_audio)
```

## One possible way of preprocessing --- MFCC

Mel-frequency cepstral coefficients.

```{r, MFCC}
sr = sample_audio@samp.rate         # samp rate in Hz
 
 
 mfcc.m = melfcc(sample_audio, sr = sr,
     wintime = 0.015,        # Window length
     hoptime = 0.005,        # Successive windown inbetween
   # numcep = 3,             # By default it will be 12 features
     sumpower = TRUE,        # frequence scale transformation based on powerspectrum
     nbands = 40,            # Number of spectra bands, filter banks
     bwidth = 1,             # Width of spectral bands
     preemph = 0.95,         # pre Emphasis
     frames_in_rows = TRUE)
   
# Determine duration
dur = length(mfcc.m)/sample_audio@samp.rate
dur # in seconds
# d=Determine sample rate
fs = sample_audio@samp.rate
fs # in Hz
## Spectrogram parameters
nfft = 512    #Fast Fourier Transformation size can be 512 (default), 1024 or 2048.
window = 1500
overlap = 500

# Creater a global function called 'spectrogram'
spectrogram = function(a) {
# Define Parameters
spec = specgram(x = a,
                n = nfft,
                Fs = fs,
                window = window,
                overlap = overlap)
# Structure of 'spec'
str(spec)
P = abs(spec$S)
# Normalize
P = P/max(P)     # If we do without abs(*) it will creat NA
# Convert to dB
P = 10*log10(P)
# config time axis
t = spec$t
# plot spectrogram
imagep(x = t,
       y = spec$f,
       z = t(P),
       col = oce.colorsViridis,
       ylab = 'Frequency in Hz',
       xlab = 'Time in Sec',
       main = 'Spectrogram',
       drawPalette = T,
       decimate = F)
}
# Spectrogram without MFCC
without.mfcc = spectrogram(as.matrix(sample_audio@left))
# Spectrogram with MFCC
with.mfcc = spectrogram(mfcc.m)
```

After comparing both the spectrogram, we can clearly identify that frequencies are converted to the Mel frequency scale.

# Possible Statistical Methods

## Cosine Similarity

After obtaining MFCC, we will use cluster algorithm to cluster the audios. The distance that we defined would be, $$
\cos(x,y) = \frac{x\times y}{|x||y|}
$$

which is called cosine similarity. The $x$ and $y$ are two different feature matrix extracted from the original two sample audios.

## Cluster algorithm

The possbile cluster algorithm would like to use is,

1.  K-means
2.  Hierarchical cluster

# Computational steps

      Data
       |
    /  |  \
    Preproccessing  (Parallel computation) 
    \  |  /
       |
    Cluster

# P.S

```{r}
spectro(sample_audio)
```

1.  We might delete the low frequency noises since the bird song usually has the highest frequency.

2.  We might delete the bird categories whose number of files is smaller than 50.

# Github Repository
[https://github.com/wennroy/Stat605_Group4project_PSW](https://github.com/wennroy/Stat605_Group4project_PSW)
